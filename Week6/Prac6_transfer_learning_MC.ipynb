{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6: Transfer learning\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning\n",
    "\n",
    "Reference: [Machine Learning Mastery](https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/)\n",
    "\n",
    "- Transfer learning is a way to speed up the training process by re-using model weights that were learned using standard computer vision benchmark datasets. \n",
    "- Transfer learning uses models trained on a similar problem as a starting point for another related problem e.g.  useful when the input to the model is the same (e.g. images), but the classification problem is different e.g., a model trained to classify penguins vs swans may be applied to a cats vs dogs setting. \n",
    "- Transfer learning decreases training time. \n",
    "\n",
    "#### Image Recognition using Transfer Learning\n",
    "\n",
    "- We can access pre-trained models and model weights for transfer learning via the [Keras Application API](https://keras.io/api/applications/)\n",
    "- These models can be used as the basis for transfer learning in computer viosions applications because:\n",
    "    - They have been pre-trained to extract generic features from photographs\n",
    "    - They have state of the art performance\n",
    "    - They are easily accessible \n",
    "\n",
    "\n",
    "#### Data \n",
    "\n",
    "- We will use the dogs and cats data that we used in weeks 4 and 5. \n",
    "- First, we get the data and save in the local notebook instance. \n",
    "- As per weeks 4 and 5, we will unzip the data, format the directories and create a valisdation dataset in the local instance.\n",
    "- The code below was run on an **ml_p2_xlarge EC2 instance**\n",
    "- The next 5 cells should be run in the terminal in jupyterlab (notified by a !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip dogs-vs-cats.zip\n",
    "! unzip train.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd train \n",
    "! mkdir dog cat\n",
    "! find . -name 'dog.*' -exec mv {} dog \\;\n",
    "! find . -name 'cat.*' -exec mv {} cat \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p val/dog val/cat #make dog and cat directories in val\n",
    "! ls train/dog | sort -R |tail -5000 | while read file; do mv train/dog/$file val/dog; done\n",
    "! ls train/cat | sort -R |tail -5000 | while read file; do mv train/cat/$file val/cat; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.42.1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker #import sagemaker\n",
    "print(sagemaker.__version__) #print the sagemaker version\n",
    "sess = sagemaker.Session() ### Manages interactions with the Amazon SageMaker APIs and \n",
    "                           ### any other AWS services needed e.g. S3\n",
    "role = sagemaker.get_execution_role() ### Get and save the IAM role as environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg16 model used for transfer learning on the dogs and cats dataset\n",
    "import sys\n",
    "import os\n",
    "import keras\n",
    "from matplotlib import pyplot\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using pre-trained VGG16 model \n",
    "\n",
    "- The VGG16 model was trained on a ImageNet challenge dataset.\n",
    "- The input images have a shape 224 x224 pixels.\n",
    "\n",
    "More details are  https://keras.io/api/applications/\n",
    "\n",
    "![VGG structure](VGG.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For this example of transfer learning, we will hold the weights of all of the convolutional layers fixed during training, and only train new fully connected layers that are for image classification. \n",
    "    - Note that transfer learning is very flexible in terms of: \n",
    "    - which layers we keep \n",
    "    - whether we fix the weights of use them as a starting point\n",
    "- Here, we will loading the VGG-16 model, removing the fully connected layers from the output-end of the model, then adding the new fully connected layers to make a binary prediction. \n",
    "- So, we are using the we may wish to use the VGG16 model layers, and adding and training new layers of the model without updating the weights of the VGG16 layers. This means that the new output layers to learn to interpret the pre-learned features of the VGG16 model.\n",
    "- It will take approximately 20 minutes to run\n",
    "\n",
    "\n",
    "#### Step 1: Load the model \n",
    "- The first step is to load the model using the Keras API. IN this case we will use the VGG16 model called using the ```VGG16``` function Arguments to consider: \n",
    "\n",
    "    1. **include_top**: whether to include the 3 fully-connected layers at the top of the network that are used to make predictions. We won't include one, allowing a new fully connected output layer to be added and trained. \n",
    "    2. **input_shape**: optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with channels_last data format) or (3, 224, 224) (with channels_first data format). It should have exactly 3 input channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value.\n",
    "    3. **weights**: one of None (random initialization), 'imagenet' (pre-training on ImageNet), or the path to the weights file to be loaded.\n",
    "    4. **classes**: optional number of classes to classify images into, only to be specified if include_top is True, and if no weights argument is specified.\n",
    "    5. **classifier_activation**: A str or callable. The activation function to use on the \"top\" layer. Ignored unless include_top=True. Set classifier_activation=None to return the logits of the \"top\" layer. When loading pretrained weights, classifier_activation can only be None or \"softmax\".\n",
    "\n",
    "- Next, we **define which layers are trainable** - we are going to keep the weights of the VGG16 model untrainable. This is achived by setting  defining the ```trainable``` property as ```False```. \n",
    "\n",
    "- We then add the new classification layers. We first flatten the output of the last pooling layer of the VGG16 model, and add fully connected, dense layers. \n",
    "\n",
    "- We then compile the new layers but selected a optimiser, a loss function and which metrics to assess performance by. \n",
    "\n",
    "#### Step 2: Define plots\n",
    "\n",
    "The next section of code defines how the results will be plotted - it will generate 2 graphs, one that shows loss and one that shows accuracy. Results on the training data are showed in blue, and results on the validation data are shown in orange. \n",
    "\n",
    "\n",
    "### Step 3: Train the model\n",
    "\n",
    "- The final section of code is to train the model. \n",
    "- Before training, we need to prepare the data so it is in the correct format for the VGG16 model. \n",
    "    - The model also expects images mean centered - *i.e.* to have the mean pixel values from each channel (red, green, and blue) as calculated on the ImageNet training dataset subtracted from the input.\n",
    "    - We can do this using ```ImageDataGenerator``` by setting the “featurewise_center” argument to “True” and manually specifying the mean pixel values to use when centering as the mean values from the ImageNet training dataset: [123.68, 116.779, 103.939].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15000 images belonging to 2 classes.\n",
      "Found 10000 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "235/235 [==============================] - 214s 912ms/step - loss: 5.6754 - acc: 0.6449 - val_loss: 0.5502 - val_acc: 0.9606\n",
      "Epoch 2/5\n",
      "235/235 [==============================] - 214s 911ms/step - loss: 0.5395 - acc: 0.9606 - val_loss: 0.3703 - val_acc: 0.9716\n",
      "Epoch 3/5\n",
      "235/235 [==============================] - 214s 912ms/step - loss: 0.2132 - acc: 0.9752 - val_loss: 0.0722 - val_acc: 0.9740\n",
      "Epoch 4/5\n",
      "235/235 [==============================] - 213s 907ms/step - loss: 0.0440 - acc: 0.9868 - val_loss: 0.0902 - val_acc: 0.9689\n",
      "Epoch 5/5\n",
      "235/235 [==============================] - 214s 913ms/step - loss: 0.0167 - acc: 0.9963 - val_loss: 0.0734 - val_acc: 0.9751\n",
      "> 97.480\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def define_model():\n",
    "\t# load model\n",
    "\tmodel = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "\t# mark loaded layers as not trainable\n",
    "\tfor layer in model.layers:\n",
    "\t\tlayer.trainable = False\n",
    "\t# add new classifier layers\n",
    "\tflat1 = Flatten()(model.layers[-1].output)\n",
    "\tclass1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "\toutput = Dense(1, activation='sigmoid')(class1)\n",
    "\t# define new model\n",
    "\tmodel = Model(inputs=model.inputs, outputs=output)\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['acc'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_acc'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\n",
    "# Training\n",
    "# define model\n",
    "model = define_model()\n",
    "# create data generator\n",
    "datagen = ImageDataGenerator(featurewise_center=True)\n",
    "# specify imagenet mean values for centering\n",
    "datagen.mean = [123.68, 116.779, 103.939]\n",
    "# prepare iterator\n",
    "train_model = datagen.flow_from_directory('train/',class_mode='binary', batch_size=64, target_size=(224, 224))\n",
    "test_model = datagen.flow_from_directory('val/',class_mode='binary', batch_size=64, target_size=(224, 224))\n",
    "# fit model\n",
    "history = model.fit_generator(train_model, steps_per_epoch=len(train_model),validation_data=test_model, validation_steps=len(test_model), epochs=5, verbose=1)\n",
    "# evaluate model\n",
    "_, acc = model.evaluate_generator(test_model, steps=len(test_model), verbose=0)\n",
    "print('> %.3f' % (acc * 100.0))\n",
    "# learning curves\n",
    "summarize_diagnostics(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the accuracy is relatively high for the valuation dataset 97.48%\n",
    "\n",
    "\n",
    "**Note:** More computations efficient and cost saving to modify the above code into a script, and use SageMaker in Script-mode to train the model. Try this for your **homework**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model using built-in CV algorithm for RecordIO files in SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to last week, except that **use_pretrained_network** is set equal to 1. The final fully connected layer of pretrained RESET model will be reized to the number of classes in the dataset. \n",
    "\n",
    "**Note:** Not as flexible but an option if you are less confident. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic.set_hyperparameters(num_layers=18,               # 18 layers\n",
    "                       use_pretrained_model=1,      # Train from scratch\n",
    "                       num_classes=2,               # Dogs and cats\n",
    "                       num_training_samples=22500,  # Number of training samples\n",
    "                       mini_batch_size=128,\n",
    "                       epochs=5)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
